{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# from tsne_python.tsne import tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "power_spec = torch.Tensor(np.load(\"CB_power_100data_60bp_25fBin.npy\"))\n",
    "(num_bp, num_coord, num_freq, num_frame) = power_spec.shape\n",
    "pwr = torch.reshape(power_spec, (num_bp*num_coord*num_freq, num_frame)).t()\n",
    "amp = pwr.sum(dim=1)\n",
    "pwr = (pwr.t()/amp).t().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingSetSize = 50\n",
    "perplexity = 32\n",
    "sigmaTolerance = 1e-4\n",
    "maxNeighbors = 10\n",
    "\n",
    "def KL_Divergence(data):\n",
    "    (N, D) = data.shape\n",
    "    log_data = torch.log(data)\n",
    "    # CHECK FOR INF AND NAN\n",
    "    inf_idx = np.isinf(log_data)\n",
    "    nan_idx = np.isnan(log_data)\n",
    "    log_data[inf_idx] = 0\n",
    "    log_data[nan_idx] = 0\n",
    "    # COMPUTE ENTROPY\n",
    "    entropy = (data*log_data).sum(dim=0)\n",
    "    \n",
    "    D = -1.0*log_data.t()@data\n",
    "    D = (D.t() - entropy).t()/np.log(2)\n",
    "    D = D - torch.diag(torch.diag(D))\n",
    "    return D\n",
    "\n",
    "# KL Divergence\n",
    "(num_bp, num_coord, num_freq, num_frame) = power_spec.shape\n",
    "pwr = torch.reshape(power_spec, (num_bp*num_coord*num_freq, num_frame))\n",
    "amp = pwr.sum(dim=0)\n",
    "pwr = pwr/amp\n",
    "interval = round(num_frame/trainingSetSize)\n",
    "train_pwr = pwr[0::interval]\n",
    "train_amp = amp[0::interval]\n",
    "D = KL_Divergence(pwr)\n",
    "# tSNE\n",
    "D = (D/torch.max(D)).pow(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.loadtxt(\"tsne_python/mnist2500_X.txt\")\n",
    "X.shape\n",
    "# Y = tsne(X=X, no_dims=2, initial_dims=50, perplexity=20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing the data using PCA...\n",
      "Computing pairwise distances...\n",
      "Computing P-values for point 0 of 100...\n",
      "Mean value of sigma: 0.002319\n",
      "Iteration 10: error is 13.015214\n",
      "Iteration 20: error is 11.561271\n",
      "Iteration 30: error is 11.912154\n",
      "Iteration 40: error is 11.821478\n",
      "Iteration 50: error is 11.521408\n",
      "Iteration 60: error is 11.444386\n",
      "Iteration 70: error is 11.951198\n",
      "Iteration 80: error is 11.827529\n",
      "Iteration 90: error is 11.907067\n",
      "Iteration 100: error is 12.245178\n",
      "Iteration 110: error is 1.644884\n",
      "Iteration 120: error is 1.332422\n",
      "Iteration 130: error is 1.059904\n",
      "Iteration 140: error is 0.911998\n",
      "Iteration 150: error is 0.780692\n",
      "Iteration 160: error is 0.698864\n",
      "Iteration 170: error is 0.594606\n",
      "Iteration 180: error is 0.533901\n",
      "Iteration 190: error is 0.507500\n",
      "Iteration 200: error is 0.475287\n",
      "Iteration 210: error is 0.425850\n",
      "Iteration 220: error is 0.431891\n",
      "Iteration 230: error is 0.398115\n",
      "Iteration 240: error is 0.388121\n",
      "Iteration 250: error is 0.372229\n",
      "Iteration 260: error is 0.366724\n",
      "Iteration 270: error is 0.363685\n",
      "Iteration 280: error is 0.360007\n",
      "Iteration 290: error is 0.357387\n",
      "Iteration 300: error is 0.355174\n",
      "Iteration 310: error is 0.349895\n",
      "Iteration 320: error is 0.346555\n",
      "Iteration 330: error is 0.343803\n",
      "Iteration 340: error is 0.343285\n",
      "Iteration 350: error is 0.343095\n",
      "Iteration 360: error is 0.342948\n",
      "Iteration 370: error is 0.342773\n",
      "Iteration 380: error is 0.342560\n",
      "Iteration 390: error is 0.342308\n",
      "Iteration 400: error is 0.342019\n",
      "Iteration 410: error is 0.341707\n",
      "Iteration 420: error is 0.341371\n",
      "Iteration 430: error is 0.340995\n",
      "Iteration 440: error is 0.340182\n",
      "Iteration 450: error is 0.339000\n",
      "Iteration 460: error is 0.338490\n",
      "Iteration 470: error is 0.338174\n",
      "Iteration 480: error is 0.337860\n",
      "Iteration 490: error is 0.337469\n",
      "Iteration 500: error is 0.336961\n",
      "Iteration 510: error is 0.336410\n",
      "Iteration 520: error is 0.335825\n",
      "Iteration 530: error is 0.335181\n",
      "Iteration 540: error is 0.333866\n",
      "Iteration 550: error is 0.331745\n",
      "Iteration 560: error is 0.330979\n",
      "Iteration 570: error is 0.330432\n",
      "Iteration 580: error is 0.329878\n",
      "Iteration 590: error is 0.329193\n",
      "Iteration 600: error is 0.328624\n",
      "Iteration 610: error is 0.328133\n",
      "Iteration 620: error is 0.323177\n",
      "Iteration 630: error is 0.320999\n",
      "Iteration 640: error is 0.320142\n",
      "Iteration 650: error is 0.320003\n",
      "Iteration 660: error is 0.319971\n",
      "Iteration 670: error is 0.317814\n",
      "Iteration 680: error is 0.316176\n",
      "Iteration 690: error is 0.315698\n",
      "Iteration 700: error is 0.315316\n",
      "Iteration 710: error is 0.315245\n",
      "Iteration 720: error is 0.315228\n",
      "Iteration 730: error is 0.315224\n",
      "Iteration 740: error is 0.315223\n",
      "Iteration 750: error is 0.315223\n",
      "Iteration 760: error is 0.315222\n",
      "Iteration 770: error is 0.315222\n",
      "Iteration 780: error is 0.315222\n",
      "Iteration 790: error is 0.315221\n",
      "Iteration 800: error is 0.315221\n",
      "Iteration 810: error is 0.315221\n",
      "Iteration 820: error is 0.315221\n",
      "Iteration 830: error is 0.315221\n",
      "Iteration 840: error is 0.315221\n",
      "Iteration 850: error is 0.315221\n",
      "Iteration 860: error is 0.315221\n",
      "Iteration 870: error is 0.315221\n",
      "Iteration 880: error is 0.315221\n",
      "Iteration 890: error is 0.315221\n",
      "Iteration 900: error is 0.315221\n",
      "Iteration 910: error is 0.315221\n",
      "Iteration 920: error is 0.315221\n",
      "Iteration 930: error is 0.315221\n",
      "Iteration 940: error is 0.315221\n",
      "Iteration 950: error is 0.315221\n",
      "Iteration 960: error is 0.315221\n",
      "Iteration 970: error is 0.315221\n",
      "Iteration 980: error is 0.315221\n",
      "Iteration 990: error is 0.315221\n",
      "Iteration 1000: error is 0.315221\n"
     ]
    }
   ],
   "source": [
    "Y_pwr = tsne(X=pwr, no_dims=2, initial_dims=50, perplexity=20.0, max_iter=1000)\n",
    "plt.scatter(Y_pwr[:,0], Y_pwr[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVIAEBHJlAKAiEimFABERDL1/9WgX5tG81qSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1238cc048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#  tsne.py\n",
    "#\n",
    "# Implementation of t-SNE in Python. The implementation was tested on Python\n",
    "# 2.7.10, and it requires a working installation of NumPy. The implementation\n",
    "# comes with an example on the MNIST dataset. In order to plot the\n",
    "# results of this example, a working installation of matplotlib is required.\n",
    "#\n",
    "# The example can be run by executing: `ipython tsne.py`\n",
    "#\n",
    "#\n",
    "#  Created by Laurens van der Maaten on 20-12-08.\n",
    "#  Copyright (c) 2008 Tilburg University. All rights reserved.\n",
    "\n",
    "import numpy as np\n",
    "import pylab\n",
    "\n",
    "\n",
    "def Hbeta(D=np.array([]), beta=1.0):\n",
    "    \"\"\"\n",
    "        Compute the perplexity and the P-row for a specific value of the\n",
    "        precision of a Gaussian distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute P-row and corresponding perplexity\n",
    "    P = np.exp(-D.copy() * beta)\n",
    "    sumP = sum(P)\n",
    "    H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "    P = P / sumP\n",
    "    return H, P\n",
    "\n",
    "\n",
    "def x2p(X=np.array([]), tol=1e-5, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Performs a binary search to get P-values in such a way that each\n",
    "        conditional Gaussian has the same perplexity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize some variables\n",
    "    print(\"Computing pairwise distances...\")\n",
    "    (n, d) = X.shape\n",
    "    sum_X = np.sum(np.square(X), 1)\n",
    "    D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "    P = np.zeros((n, n))\n",
    "    beta = np.ones((n, 1))\n",
    "    logU = np.log(perplexity)\n",
    "\n",
    "    # Loop over all datapoints\n",
    "    for i in range(n):\n",
    "\n",
    "        # Print progress\n",
    "        if i % 500 == 0:\n",
    "            print(\"Computing P-values for point %d of %d...\" % (i, n))\n",
    "\n",
    "        # Compute the Gaussian kernel and entropy for the current precision\n",
    "        betamin = -np.inf\n",
    "        betamax = np.inf\n",
    "        Di = D[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))]\n",
    "        (H, thisP) = Hbeta(Di, beta[i])\n",
    "\n",
    "        # Evaluate whether the perplexity is within tolerance\n",
    "        Hdiff = H - logU\n",
    "        tries = 0\n",
    "        while np.abs(Hdiff) > tol and tries < 50:\n",
    "\n",
    "            # If not, increase or decrease precision\n",
    "            if Hdiff > 0:\n",
    "                betamin = beta[i].copy()\n",
    "                if betamax == np.inf or betamax == -np.inf:\n",
    "                    beta[i] = beta[i] * 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamax) / 2.\n",
    "            else:\n",
    "                betamax = beta[i].copy()\n",
    "                if betamin == np.inf or betamin == -np.inf:\n",
    "                    beta[i] = beta[i] / 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamin) / 2.\n",
    "\n",
    "            # Recompute the values\n",
    "            (H, thisP) = Hbeta(Di, beta[i])\n",
    "            Hdiff = H - logU\n",
    "            tries += 1\n",
    "\n",
    "        # Set the final row of P\n",
    "        P[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))] = thisP\n",
    "\n",
    "    # Return final P-matrix\n",
    "    print(\"Mean value of sigma: %f\" % np.mean(np.sqrt(1 / beta)))\n",
    "    return P\n",
    "\n",
    "\n",
    "def pca(X=np.array([]), no_dims=50):\n",
    "    \"\"\"\n",
    "        Runs PCA on the NxD array X in order to reduce its dimensionality to\n",
    "        no_dims dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Preprocessing the data using PCA...\")\n",
    "    (n, d) = X.shape\n",
    "    X = X - np.tile(np.mean(X, 0), (n, 1))\n",
    "    (l, M) = np.linalg.eig(np.dot(X.T, X))\n",
    "    Y = np.dot(X, M[:, 0:no_dims])\n",
    "    return Y\n",
    "\n",
    "\n",
    "def tsne(X=np.array([]), no_dims=2, initial_dims=50, perplexity=30.0, max_iter=1000):\n",
    "    \"\"\"\n",
    "        Runs t-SNE on the dataset in the NxD array X to reduce its\n",
    "        dimensionality to no_dims dimensions. The syntaxis of the function is\n",
    "        `Y = tsne.tsne(X, no_dims, perplexity), where X is an NxD NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check inputs\n",
    "    if isinstance(no_dims, float):\n",
    "        print(\"Error: array X should have type float.\")\n",
    "        return -1\n",
    "    if round(no_dims) != no_dims:\n",
    "        print(\"Error: number of dimensions should be an integer.\")\n",
    "        return -1\n",
    "\n",
    "    # Initialize variables\n",
    "    X = pca(X, initial_dims).real\n",
    "    (n, d) = X.shape\n",
    "    initial_momentum = 0.5\n",
    "    final_momentum = 0.8\n",
    "    eta = 500\n",
    "    min_gain = 0.01\n",
    "    Y = np.random.randn(n, no_dims)\n",
    "    dY = np.zeros((n, no_dims))\n",
    "    iY = np.zeros((n, no_dims))\n",
    "    gains = np.ones((n, no_dims))\n",
    "\n",
    "    # Compute P-values\n",
    "    P = x2p(X, 1e-5, perplexity)\n",
    "    P = P + np.transpose(P)\n",
    "    P = P / np.sum(P)\n",
    "    P = P * 4.\t\t\t\t\t\t\t\t\t# early exaggeration\n",
    "    P = np.maximum(P, 1e-12)\n",
    "\n",
    "    # Run iterations\n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        # Compute pairwise affinities\n",
    "        sum_Y = np.sum(np.square(Y), 1)\n",
    "        num = -2. * np.dot(Y, Y.T)\n",
    "        num = 1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y))\n",
    "        num[range(n), range(n)] = 0.\n",
    "        Q = num / np.sum(num)\n",
    "        Q = np.maximum(Q, 1e-12)\n",
    "\n",
    "        # Compute gradient\n",
    "        PQ = P - Q\n",
    "        for i in range(n):\n",
    "            dY[i, :] = np.sum(np.tile(PQ[:, i] * num[:, i], (no_dims, 1)).T * (Y[i, :] - Y), 0)\n",
    "\n",
    "        # Perform the update\n",
    "        if iter < 20:\n",
    "            momentum = initial_momentum\n",
    "        else:\n",
    "            momentum = final_momentum\n",
    "        gains = (gains + 0.2) * ((dY > 0.) != (iY > 0.)) + \\\n",
    "                (gains * 0.8) * ((dY > 0.) == (iY > 0.))\n",
    "        gains[gains < min_gain] = min_gain\n",
    "        iY = momentum * iY - eta * (gains * dY)\n",
    "        Y = Y + iY\n",
    "        Y = Y - np.tile(np.mean(Y, 0), (n, 1))\n",
    "\n",
    "        # Compute current value of cost function\n",
    "        if (iter + 1) % 10 == 0:\n",
    "            C = np.sum(P * np.log(P / Q))\n",
    "            print(\"Iteration %d: error is %f\" % (iter + 1, C))\n",
    "\n",
    "        # Stop lying about P-values\n",
    "        if iter == 100:\n",
    "            P = P / 4.\n",
    "\n",
    "    # Return solution\n",
    "    return Y\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"Run Y = tsne.tsne(X, no_dims, perplexity) to perform t-SNE on your dataset.\")\n",
    "#     print(\"Running example on 2,500 MNIST digits...\")\n",
    "#     X = np.loadtxt(\"mnist2500_X.txt\")\n",
    "#     labels = np.loadtxt(\"mnist2500_labels.txt\")\n",
    "#     Y = tsne(X, 2, 50, 20.0)\n",
    "#     pylab.scatter(Y[:, 0], Y[:, 1], 20, labels)\n",
    "#     pylab.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
